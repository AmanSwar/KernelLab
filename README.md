# KernelLab
making GPU go BRRRRRRRR......
collection of high-performance CUDA implementations, ranging from naive to highly optimized versions ((using shared memory, warp-level optimizations, vectorization, tensor cores, etc).
Each kernel is benchmarked against different levels of optimization and compared to state-of-the-art (SOTA) kernels implemented in popular High Performance libraries like cuBLAS and PyTorch.

## FEATURES
	- [x] naive blur
	- [ ] gaussian blur
	- [x] greyscale
	- [x] vector addition
	- [x] GEMM
	- [x] matrix transpose
	- [x] reduction kernel
	- [x] 2d conv
	- [x] 3d conv
	- [x] softmax
	- [ ] self attention
	- [ ] flash attention
	- [x] relu
	- [ ] layer Norm
	- [ ] BFS
	- [ ] DFS
	- [ ] Sorting
